{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7\n",
    "\n",
    "**Harvard University**<br>\n",
    "**Fall 2018**<br>\n",
    "**Instructors: Rahul Dave**<br>\n",
    "**Due Date: ** Saturday, October 27th, 2018 at 11:59pm\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- Upload your final answers in the form of a Jupyter notebook containing all work to Canvas.\n",
    "\n",
    "- Structure your notebook and your work to maximize readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators\n",
    "\n",
    "** Place the name of everyone who's submitting this assignment here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.special\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "## Standard boilerplate to import torch and torch related modules\n",
    "import torch\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Mon pays c'est l'MNIST. Mon cœur est brise de Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [*MNIST* dataset](https://en.wikipedia.org/wiki/MNIST_database) is one of the classic datasets in Machine Learning and is often one of the first datasets against which new classification algorithms test themselves.  It consists of 70,000 images of handwritten digits, each of which is 28x28 pixels. You will be using PyTorch to build a handwritten digit classifier that you will train, validate, and test with MNIST. \n",
    "\n",
    "Your classifier MUST implement a multinomial logistic regression model (using softmax). It will take as input an array of pixel values in an image and output the images most likely digit label (i.e. 0-9). You should think of the pixel values as features of the input vector.  \n",
    "\n",
    "Using the softmax formulation, your PyTorch model should computes the cost function using an L2 regularization approach (see `optim.SGD` in PyTorch or write your own cost function) and minimize the resulting cost function using mini-batch stochastic gradient descent.  We provided  extensive template code in lab.\n",
    "\n",
    "Construct and train your classifier using a batch size of 256 examples, a learning rate $\\eta$=0.1, and a regularization factor $\\lambda$=0.01.\n",
    "\n",
    "1.1. Plot 10 sample images from the MNIST dataset (to develop intuition for the feature space).\n",
    "\n",
    "1.2. Currently the MNIST dataset in Torchvision allows a Train/Test split.  Use PyTorch dataloader functionality to create a Train/Validate/Test split  of 50K/10K/10K samples.\n",
    "\n",
    "**Hint:** Lab described a way to do it keeping within the MNIST `DataLoader` workflow: the key is to pass a `SubsetRandomSampler` to `DataLoader`\n",
    "\n",
    "1.3. Construct a softmax formulation in PyTorch of multinomial logistic regression with Cross Entropy Loss.\n",
    "\n",
    "1.4. Train your model using SGD to minimize the cost function. Use as many epochs as you need to achive convergence.\n",
    "\n",
    "1.5. Plot the cross-entropy loss on the training set as a function of iteration.\n",
    "\n",
    "1.6. Using classification accuracy, evaluate how well your model is performing on the validation set at the end of each epoch. Plot this validation accuracy as the model trains.\n",
    "\n",
    "1.6. Duplicate this plot for some other values of the regularization parameter $\\lambda$. When should you stop the training for each of the different values of λ? Give an approximate answer supported by using the plots.\n",
    "\n",
    "1.7. Select what you consider the best regularization parameter and predict the labels of the test set. Compare your predictions with the given labels. What classification accuracy do you obtain on the training and test sets?\n",
    "\n",
    "1.8. What classes are most likely to be misclassified? Plot some misclassified training and test set images.\n",
    "\n",
    "**Gratuitous Titular Reference**:  The recently departed French rockstar Johnny Hallyday just posthumously released what looks to be his biggest album ever \"Mon pays c'est l'amour\".  The album sold 300,000 copies on its first day of release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.1. Plot 10 sample images from the MNIST dataset (to develop intuition for the feature space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot 10 samples from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download and transform train dataset\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST('../mnist_data', \n",
    "                                                          download=True, \n",
    "                                                          train=True,\n",
    "                                                          transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                                              transforms.Normalize((0.1307,), (0.3081,)) # normalize inputs\n",
    "                                                          ])), \n",
    "                                           batch_size=10, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4, 5, 4, 1, 6, 4, 7, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABWAAAACUCAYAAAAdzIB1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x124eab198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(24, 24))\n",
    "plt.tight_layout()\n",
    "\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(1, len(images), i+1)\n",
    "    plt.imshow(images[i, 0, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.2. Currently the MNIST dataset in Torchvision allows a Train/Test split.  Use PyTorch dataloader functionality to create a Train/Validate/Test split  of 50K/10K/10K samples.\n",
    "\n",
    "> **Hint:** Lab described a way to do it keeping within the MNIST `DataLoader` workflow: the key is to pass a `SubsetRandomSampler` to `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `random_split` instead of `SubsetRandomSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST('../mnist_data',\n",
    "                             train=True,\n",
    "                             transform=transforms.Compose([\n",
    "                                 transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                                 transforms.Normalize((0.5,), (0.5,)) # normalize inputs\n",
    "                                 ]))\n",
    "\n",
    "train, valid = torch.utils.data.random_split(mnist_train, lengths=[50000, 10000])\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=32)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=32)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../mnist_data',\n",
    "                   train=False,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "                       transforms.Normalize((0.5,), (0.5,)) # normalize inputs\n",
    "                       ])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.3. Construct a softmax formulation in PyTorch of multinomial logistic regression with Cross Entropy Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.fc = torch.nn.Linear(28*28, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits '''\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.4. Train your model using SGD to minimize the cost function. Use as many epochs as you need to achive convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_stats(model, generator, criterion):\n",
    "    \"\"\"\n",
    "    Calculate loss and accuracy\n",
    "    \n",
    "    :param model: pytorch model\n",
    "    :param genertor: data generator\n",
    "    :param criterion: loss function\n",
    "    \"\"\"\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    # For efficiency, don't calculate any gradients\n",
    "    with torch.no_grad():\n",
    "        for images, labels in iter(generator):\n",
    "            images.resize_(images.size()[0], 28*28)\n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            # Bookkeeping\n",
    "            batch_predictions = output.argmax(dim=1)\n",
    "            batch_acc = (batch_predictions == labels).double().sum()\n",
    "            \n",
    "            running_loss += loss.item() * len(images)\n",
    "            running_acc += batch_acc\n",
    "            \n",
    "            n_samples += len(images)\n",
    "            \n",
    "        return running_loss / n_samples, running_acc / n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3...  Loss: 0.6194 Accuracy: 0.8502\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6d2def3e8271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-6d2def3e8271>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, epochs, train_loader, valid_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mrunning_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;31m# Flatten images to 28*28 vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torchvision/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/torchvision/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;31m# PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# print(encoder, mode, args + extra)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoder %s not available\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "def train_model(model, epochs, train_loader, valid_loader, optimizer, criterion):\n",
    "\n",
    "    train_loss = np.empty(epochs)\n",
    "    val_loss = np.empty(epochs)\n",
    "    train_acc = np.empty(epochs)\n",
    "    val_acc = np.empty(epochs)\n",
    "\n",
    "\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "        for images, labels in iter(train_loader):\n",
    "            # Flatten images to 28*28 vector\n",
    "            images.resize_(images.size()[0], 28*28)\n",
    "\n",
    "            # Remove gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward and backward passes\n",
    "            output = model.forward(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Bookkeeping\n",
    "            predictions = output.argmax(dim=1)\n",
    "            batch_acc = (predictions == labels).double().sum()\n",
    "\n",
    "            running_loss += loss.item() * len(images)\n",
    "            running_acc += batch_acc\n",
    "\n",
    "\n",
    "        print(\"Epoch: {}/{}... \".format(e+1, epochs),\n",
    "              \"Loss: {:.4f}\".format(running_loss/50000),\n",
    "              \"Accuracy: {:.4f}\".format(running_acc/50000))\n",
    "        train_loss[e] = running_loss / 50000\n",
    "        train_acc[e] = running_acc / 50000\n",
    "        running_loss = 0\n",
    "        running_acc = 0\n",
    "\n",
    "        val_loss[e], val_acc[e] = calc_stats(model, valid_loader, criterion)\n",
    "    \n",
    "    summary_stats = pd.DataFrame({'epoch': np.arange(epochs) + 1,\n",
    "                                  'train_loss': train_loss,\n",
    "                                  'val_loss': val_loss,\n",
    "                                  'train_acc': train_acc,\n",
    "                                  'val_acc': val_acc})\n",
    "    \n",
    "    return model, summary_stats\n",
    "\n",
    "model, summary_stats = train_model(model, epochs, train_loader, valid_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.5. Plot the cross-entropy loss on the training set as a function of iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Training loss vs epochs')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEWCAYAAABbgYH9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBCMiIlGhBCMiIlHx/9mxKBkJcnT+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128d337b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(summary_stats['epoch'], summary_stats['train_loss'])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.title(\"Training loss vs epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.6. Using classification accuracy, evaluate how well your model is performing on the validation set at the end of each epoch. Plot this validation accuracy as the model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x127e65cc0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEU8v8BoiAJnYNu5DIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12cf973c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(summary_stats['epoch'], summary_stats['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.7. Duplicate this plot for some other values of the regularization parameter $\\lambda$. When should you stop the training for each of the different values of λ? Give an approximate answer supported by using the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10...  Loss: 1.9903 Accuracy: 0.3920\n",
      "Epoch: 2/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 3/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 4/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 5/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 6/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 7/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 8/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 9/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 10/10...  Loss: 1.9885 Accuracy: 0.3932\n",
      "Epoch: 1/10...  Loss: 1.0955 Accuracy: 0.7799\n",
      "Epoch: 2/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 3/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 4/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 5/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 6/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 7/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 8/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 9/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 10/10...  Loss: 1.0637 Accuracy: 0.7933\n",
      "Epoch: 1/10...  Loss: 0.6196 Accuracy: 0.8496\n",
      "Epoch: 2/10...  Loss: 0.5102 Accuracy: 0.8800\n",
      "Epoch: 3/10...  Loss: 0.5086 Accuracy: 0.8807\n",
      "Epoch: 4/10...  Loss: 0.5084 Accuracy: 0.8808\n",
      "Epoch: 5/10...  Loss: 0.5084 Accuracy: 0.8808\n",
      "Epoch: 6/10...  Loss: 0.5084 Accuracy: 0.8808\n",
      "Epoch: 7/10...  Loss: 0.5084 Accuracy: 0.8808\n",
      "Epoch: 8/10...  Loss: 0.5084 Accuracy: 0.8808\n",
      "Epoch: 9/10...  Loss: 0.5084 Accuracy: 0.8808\n",
      "Epoch: 10/10...  Loss: 0.5084 Accuracy: 0.8808\n",
      "Epoch: 1/10...  Loss: 0.5400 Accuracy: 0.8571\n",
      "Epoch: 2/10...  Loss: 0.3731 Accuracy: 0.8969\n",
      "Epoch: 3/10...  Loss: 0.3508 Accuracy: 0.9033\n",
      "Epoch: 4/10...  Loss: 0.3408 Accuracy: 0.9062\n",
      "Epoch: 5/10...  Loss: 0.3353 Accuracy: 0.9077\n",
      "Epoch: 6/10...  Loss: 0.3319 Accuracy: 0.9083\n",
      "Epoch: 7/10...  Loss: 0.3296 Accuracy: 0.9091\n",
      "Epoch: 8/10...  Loss: 0.3281 Accuracy: 0.9096\n",
      "Epoch: 9/10...  Loss: 0.3270 Accuracy: 0.9101\n",
      "Epoch: 10/10...  Loss: 0.3262 Accuracy: 0.9104\n",
      "Epoch: 1/10...  Loss: 0.5322 Accuracy: 0.8581\n",
      "Epoch: 2/10...  Loss: 0.3596 Accuracy: 0.8990\n",
      "Epoch: 3/10...  Loss: 0.3330 Accuracy: 0.9058\n",
      "Epoch: 4/10...  Loss: 0.3194 Accuracy: 0.9089\n",
      "Epoch: 5/10...  Loss: 0.3107 Accuracy: 0.9114\n",
      "Epoch: 6/10...  Loss: 0.3045 Accuracy: 0.9134\n",
      "Epoch: 7/10...  Loss: 0.2998 Accuracy: 0.9155\n",
      "Epoch: 8/10...  Loss: 0.2960 Accuracy: 0.9170\n",
      "Epoch: 9/10...  Loss: 0.2929 Accuracy: 0.9180\n",
      "Epoch: 10/10...  Loss: 0.2902 Accuracy: 0.9188\n",
      "Epoch: 1/10...  Loss: 0.5330 Accuracy: 0.8564\n",
      "Epoch: 2/10...  Loss: 0.3582 Accuracy: 0.8989\n",
      "Epoch: 3/10...  Loss: 0.3314 Accuracy: 0.9061\n",
      "Epoch: 4/10...  Loss: 0.3175 Accuracy: 0.9096\n",
      "Epoch: 5/10...  Loss: 0.3086 Accuracy: 0.9124\n",
      "Epoch: 6/10...  Loss: 0.3022 Accuracy: 0.9143\n",
      "Epoch: 7/10...  Loss: 0.2972 Accuracy: 0.9160\n",
      "Epoch: 8/10...  Loss: 0.2933 Accuracy: 0.9169\n",
      "Epoch: 9/10...  Loss: 0.2899 Accuracy: 0.9183\n",
      "Epoch: 10/10...  Loss: 0.2871 Accuracy: 0.9196\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>lambda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.39204</td>\n",
       "      <td>1.990334</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.39318</td>\n",
       "      <td>1.988514</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>2.062392</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.77994</td>\n",
       "      <td>1.095541</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.7140</td>\n",
       "      <td>1.109369</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84960</td>\n",
       "      <td>0.619560</td>\n",
       "      <td>0.8738</td>\n",
       "      <td>0.519574</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.88000</td>\n",
       "      <td>0.510164</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>0.514642</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.88072</td>\n",
       "      <td>0.508560</td>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.514227</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.88084</td>\n",
       "      <td>0.508416</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.514175</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.88082</td>\n",
       "      <td>0.508399</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.514167</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.88082</td>\n",
       "      <td>0.508396</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.88082</td>\n",
       "      <td>0.508396</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.88082</td>\n",
       "      <td>0.508396</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.88082</td>\n",
       "      <td>0.508396</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.88082</td>\n",
       "      <td>0.508396</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85710</td>\n",
       "      <td>0.540005</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>0.392381</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.89690</td>\n",
       "      <td>0.373066</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>0.358985</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90332</td>\n",
       "      <td>0.350833</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.346533</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.90616</td>\n",
       "      <td>0.340840</td>\n",
       "      <td>0.9016</td>\n",
       "      <td>0.340197</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.90766</td>\n",
       "      <td>0.335296</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.336514</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.90830</td>\n",
       "      <td>0.331882</td>\n",
       "      <td>0.9045</td>\n",
       "      <td>0.334206</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.90910</td>\n",
       "      <td>0.329642</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.332687</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.90960</td>\n",
       "      <td>0.328108</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>0.331650</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.91014</td>\n",
       "      <td>0.327022</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.330923</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.91042</td>\n",
       "      <td>0.326234</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>0.330402</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85812</td>\n",
       "      <td>0.532191</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.379620</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.89900</td>\n",
       "      <td>0.359576</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.342506</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90578</td>\n",
       "      <td>0.333040</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.327047</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.90892</td>\n",
       "      <td>0.319407</td>\n",
       "      <td>0.9069</td>\n",
       "      <td>0.318158</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.91140</td>\n",
       "      <td>0.310697</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>0.312270</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.91344</td>\n",
       "      <td>0.304486</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>0.308042</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.91548</td>\n",
       "      <td>0.299750</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.304840</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.91696</td>\n",
       "      <td>0.295971</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.302323</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.91798</td>\n",
       "      <td>0.292857</td>\n",
       "      <td>0.9122</td>\n",
       "      <td>0.300290</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.91876</td>\n",
       "      <td>0.290228</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>0.298612</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.85640</td>\n",
       "      <td>0.533031</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.378249</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.89890</td>\n",
       "      <td>0.358172</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>0.340939</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.90610</td>\n",
       "      <td>0.331382</td>\n",
       "      <td>0.9048</td>\n",
       "      <td>0.325280</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.90964</td>\n",
       "      <td>0.317515</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>0.316223</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.91236</td>\n",
       "      <td>0.308586</td>\n",
       "      <td>0.9097</td>\n",
       "      <td>0.310194</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.91428</td>\n",
       "      <td>0.302168</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.305844</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.91596</td>\n",
       "      <td>0.297231</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>0.302537</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.91686</td>\n",
       "      <td>0.293256</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.299928</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.91830</td>\n",
       "      <td>0.289948</td>\n",
       "      <td>0.9134</td>\n",
       "      <td>0.297814</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.91956</td>\n",
       "      <td>0.287127</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>0.296064</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_acc  train_loss  val_acc  val_loss   lambda\n",
       "0      1    0.39204    1.990334   0.2051  2.062392  10.0000\n",
       "1      2    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "2      3    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "3      4    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "4      5    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "5      6    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "6      7    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "7      8    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "8      9    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "9     10    0.39318    1.988514   0.2051  2.062392  10.0000\n",
       "0      1    0.77994    1.095541   0.7140  1.109369   1.0000\n",
       "1      2    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "2      3    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "3      4    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "4      5    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "5      6    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "6      7    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "7      8    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "8      9    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "9     10    0.79326    1.063654   0.7140  1.109369   1.0000\n",
       "0      1    0.84960    0.619560   0.8738  0.519574   0.1000\n",
       "1      2    0.88000    0.510164   0.8759  0.514642   0.1000\n",
       "2      3    0.88072    0.508560   0.8758  0.514227   0.1000\n",
       "3      4    0.88084    0.508416   0.8755  0.514175   0.1000\n",
       "4      5    0.88082    0.508399   0.8755  0.514167   0.1000\n",
       "5      6    0.88082    0.508396   0.8754  0.514166   0.1000\n",
       "6      7    0.88082    0.508396   0.8754  0.514166   0.1000\n",
       "7      8    0.88082    0.508396   0.8754  0.514166   0.1000\n",
       "8      9    0.88082    0.508396   0.8754  0.514166   0.1000\n",
       "9     10    0.88082    0.508396   0.8754  0.514166   0.1000\n",
       "0      1    0.85710    0.540005   0.8902  0.392381   0.0100\n",
       "1      2    0.89690    0.373066   0.8975  0.358985   0.0100\n",
       "2      3    0.90332    0.350833   0.8997  0.346533   0.0100\n",
       "3      4    0.90616    0.340840   0.9016  0.340197   0.0100\n",
       "4      5    0.90766    0.335296   0.9035  0.336514   0.0100\n",
       "5      6    0.90830    0.331882   0.9045  0.334206   0.0100\n",
       "6      7    0.90910    0.329642   0.9051  0.332687   0.0100\n",
       "7      8    0.90960    0.328108   0.9058  0.331650   0.0100\n",
       "8      9    0.91014    0.327022   0.9059  0.330923   0.0100\n",
       "9     10    0.91042    0.326234   0.9061  0.330402   0.0100\n",
       "0      1    0.85812    0.532191   0.8912  0.379620   0.0010\n",
       "1      2    0.89900    0.359576   0.9000  0.342506   0.0010\n",
       "2      3    0.90578    0.333040   0.9039  0.327047   0.0010\n",
       "3      4    0.90892    0.319407   0.9069  0.318158   0.0010\n",
       "4      5    0.91140    0.310697   0.9086  0.312270   0.0010\n",
       "5      6    0.91344    0.304486   0.9096  0.308042   0.0010\n",
       "6      7    0.91548    0.299750   0.9109  0.304840   0.0010\n",
       "7      8    0.91696    0.295971   0.9116  0.302323   0.0010\n",
       "8      9    0.91798    0.292857   0.9122  0.300290   0.0010\n",
       "9     10    0.91876    0.290228   0.9123  0.298612   0.0010\n",
       "0      1    0.85640    0.533031   0.8930  0.378249   0.0001\n",
       "1      2    0.89890    0.358172   0.9005  0.340939   0.0001\n",
       "2      3    0.90610    0.331382   0.9048  0.325280   0.0001\n",
       "3      4    0.90964    0.317515   0.9074  0.316223   0.0001\n",
       "4      5    0.91236    0.308586   0.9097  0.310194   0.0001\n",
       "5      6    0.91428    0.302168   0.9105  0.305844   0.0001\n",
       "6      7    0.91596    0.297231   0.9118  0.302537   0.0001\n",
       "7      8    0.91686    0.293256   0.9130  0.299928   0.0001\n",
       "8      9    0.91830    0.289948   0.9134  0.297814   0.0001\n",
       "9     10    0.91956    0.287127   0.9138  0.296064   0.0001"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas = [10.0, 1.0, 0.1, 0.01, 0.001, 0.0001]\n",
    "def eval_lambda(reg):\n",
    "    \"\"\"\n",
    "    Evaluate single regularization parameter\n",
    "    \"\"\"\n",
    "    model_new = Network()\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model_new.parameters(), lr=0.01, weight_decay=reg)\n",
    "    \n",
    "    _, summary_stats = train_model(model_new, epochs=10, train_loader=train_loader, valid_loader=valid_loader,\n",
    "                                   optimizer=optimizer, criterion=criterion)\n",
    "    \n",
    "    summary_stats['lambda'] = reg\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "\n",
    "results = pd.concat([eval_lambda(reg) for reg in lambdas])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12f7d1080>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAADQCAYAAAAalMCAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wduzFbCg8/7fgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f328128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foo = pd.melt(results, id_vars=['epoch', 'lambda'])\n",
    "g = sns.FacetGrid(foo, hue=\"lambda\", col='variable', sharey=False)\n",
    "g.map(plt.plot, \"epoch\", \"value\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.8. Select what you consider the best regularization parameter and predict the labels of the test set. Compare your predictions with the given labels. What classification accuracy do you obtain on the training and test sets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1.9. What classes are most likely to be misclassified? Plot some misclassified training and test set images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: MNIST MLP!  Find out what that means to me.  MNIST MLP!  Take care, TCB!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multilayer perceptron can be understood as a logistic regression classifier in which the input is first transformed using a learnt non-linear transformation. The non-linear transformation is often chosen to be either the logistic function or the $\\tanh$ function or the RELU function, and its purpose is to project the data into a space where it becomes linearly separable. The output of this so-called hidden layer is then passed to the logistic regression graph that we have constructed in the first problem. \n",
    "\n",
    "![](http://deeplearning.net/tutorial/_images/mlp.png)\n",
    "\n",
    "We'll construct a model with **1 hidden layer**. That is, you will have an input layer, then a hidden layer with the nonlinearity, and finally an output layer with cross-entropy loss (or equivalently log-softmax activation with a negative log likelihood loss).\n",
    "\n",
    "2.1. Using a similar architecture as in Question 1 and the same training, validation and test sets, build a PyTorch model for the multilayer perceptron. Use the $\\tanh$ function as the non-linear activation function. \n",
    "\n",
    "2.2. The initialization of the weights matrix for the hidden layer must assure that the units (neurons) of the perceptron operate in a regime where information gets propagated. For the $\\tanh$ function, you may find it advisable to initialize with the interval $\\left[-\\sqrt{\\frac{6}{fan_{in}+fan_{out}}},\\sqrt{\\frac{6}{fan_{in}+fan_{out}}}\\right]$, where $fan_{in}$ is the number of units in the $(i-1)$-th layer, and $fan_{out}$ is the number of units in the i-th layer.  This is known as **Xavier Initialization**.  Use Xavier Initialization to initialize your MLP.  Feel free to use PyTorch's in-built Xavier Initialization methods.\n",
    "\n",
    "2.3. Using $\\lambda = 0.01$ to compare with Question 1, experiment with the learning rate (try 0.1 and 0.01 for example), batch size (use 64, 128 and 256) and the number of units in your hidden layer (use between 25 and 200 units). For what combination of these parameters do you obtain the highest validation accuracy?  You may want to start with 20 epochs for running time and experiment a bit to make sure that your models reach convergence. \n",
    "\n",
    "2.4. For your best combination plot the cross-entropy loss on the training set as a function of iteration.\n",
    "\n",
    "2.5. For your best combination use classification accuracy to evaluate how well your model is performing on the validation set at the end of each epoch. Plot this validation accuracy as the model trains.\n",
    "\n",
    "2.6. Select what you consider the best set of parameters and predict the labels of the test set. Compare your predictions with the given labels. What classification accuracy do you obtain on the training and test sets?\n",
    "\n",
    "2.7. How does your test accuracy compare to that of the logistic regression classifier in Question 1?  Compare best parameters for both models.\n",
    "\n",
    "2.8. What classes are most likely to be misclassified? Plot some misclassified training and test set images.\n",
    "\n",
    "\n",
    "**Gratuitous Titular Reference**:  Respect, originally performed by Otis Redding, became a huge hit and an anthem for the recently departed \"Queen of Soul\" Aretha Franklin.  Respect is often credited with popularizing the word usages \"propers\" (a synonym for respect) and \"sock it to me\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"answer-separator\">\n",
    "------------------------\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
